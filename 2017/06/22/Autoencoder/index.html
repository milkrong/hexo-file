<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="A Simple AutoencoderWe’ll start off by building a simple autoencoder to compress the MNIST dataset. With autoencoders, we pass input data through an e">
    

    <!--Author-->
    
        <meta name="author" content="Eric Liu">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Autoencoder"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="MilkSite"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>Autoencoder - MilkSite</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about.html">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact.html">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
    </div>
</header>

        <section class="main">
            
<div class="post">

    <div class="post-header">
        <h1 class="title">
            <a href="/2017/06/22/Autoencoder/">
                Autoencoder
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2017-06-22</span>
            
            
            
        </div>
    </div>

    <div class="content">

        <!-- Gallery -->
        

        <!-- Post Content -->
        <h1 id="A-Simple-Autoencoder"><a href="#A-Simple-Autoencoder" class="headerlink" title="A Simple Autoencoder"></a>A Simple Autoencoder</h1><p>We’ll start off by building a simple autoencoder to compress the MNIST dataset. With autoencoders, we pass input data through an encoder that makes a compressed representation of the input. Then, this representation is passed through a decoder to reconstruct the input data. Generally the encoder and decoder will be built with neural networks, then trained on example data.</p>
<p>In this notebook, we’ll be build a simple network architecture for the encoder and decoder. Let’s get started by importing our libraries and getting the dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, validation_size=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<p>Below I’m plotting an example image from the MNIST dataset. These are 28x28 grayscale images of handwritten digits.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">img = mnist.train.images[<span class="number">2</span>]</div><div class="line">plt.imshow(img.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">'Greys_r'</span>)</div></pre></td></tr></table></figure>
<p>We’ll train an autoencoder with these images by flattening them into 784 length vectors. The images from this dataset are already normalized such that the values are between 0 and 1. Let’s start by building basically the simplest autoencoder with a <strong>single ReLU hidden layer</strong>. This layer will be used as the compressed representation. Then, the encoder is the input layer and the hidden layer. The decoder is the hidden layer and the output layer. Since the images are normalized between 0 and 1, we need to use a <strong>sigmoid activation on the output layer</strong> to get values matching the input.</p>
<blockquote>
<p><strong>Exercise:</strong> Build the graph for the autoencoder in the cell below. The input images will be flattened into 784 length vectors. The targets are the same as the inputs. And there should be one hidden layer with a ReLU activation and an output layer with a sigmoid activation. The loss should be calculated with the cross-entropy loss, there is a convenient TensorFlow function for this <code>tf.nn.sigmoid_cross_entropy_with_logits</code> (<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits" target="_blank" rel="external">documentation</a>). You should note that <code>tf.nn.sigmoid_cross_entropy_with_logits</code> takes the logits, but to get the reconstructed images you’ll need to pass the logits through the sigmoid function.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Size of the encoding layer (the hidden layer)</span></div><div class="line">encoding_dim = <span class="number">32</span></div><div class="line"></div><div class="line">image_size = mnist.train.images.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line">inputs_ = tf.placeholder(tf.float32, (<span class="keyword">None</span>, image_size), name=<span class="string">'inputs'</span>)</div><div class="line">targets_ = tf.placeholder(tf.float32, (<span class="keyword">None</span>, image_size), name=<span class="string">'targets'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Output of hidden layer</span></div><div class="line">encoded = tf.layers.dense(inputs_, encoding_dim, activation=tf.nn.relu)</div><div class="line"></div><div class="line"><span class="comment"># Output layer logits</span></div><div class="line">logits = tf.layers.dense(encoded, image_size, activation=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># Sigmoid output from</span></div><div class="line">decoded = tf.nn.sigmoid(logits, name=<span class="string">'output'</span>)</div><div class="line"></div><div class="line">loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)</div><div class="line">cost = tf.reduce_mean(loss)</div><div class="line">opt = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cost)</div></pre></td></tr></table></figure>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Create the session</span></div><div class="line">sess = tf.Session()</div></pre></td></tr></table></figure>
<p>Here I’ll write a bit of code to train the network. I’m not too interested in validation here, so I’ll just monitor the training loss and the test loss afterwards.</p>
<p>Calling <code>mnist.train.next_batch(batch_size)</code> will return a tuple of <code>(images, labels)</code>. We’re not concerned with the labels here, we just need the images. Otherwise this is pretty straightfoward training with TensorFlow. We initialize the variables with <code>sess.run(tf.global_variables_initializer())</code>. Then, run the optimizer and get the loss with <code>batch_cost, _ = sess.run([cost, opt], feed_dict=feed)</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">epochs = <span class="number">20</span></div><div class="line">batch_size = <span class="number">200</span></div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</div><div class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> range(mnist.train.num_examples//batch_size):</div><div class="line">        batch = mnist.train.next_batch(batch_size)</div><div class="line">        feed = &#123;inputs_: batch[<span class="number">0</span>], targets_: batch[<span class="number">0</span>]&#125;</div><div class="line">        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)</div><div class="line"></div><div class="line">        print(<span class="string">"Epoch: &#123;&#125;/&#123;&#125;..."</span>.format(e+<span class="number">1</span>, epochs),</div><div class="line">              <span class="string">"Training loss: &#123;:.4f&#125;"</span>.format(batch_cost))</div></pre></td></tr></table></figure>
<h2 id="Checking-out-the-results"><a href="#Checking-out-the-results" class="headerlink" title="Checking out the results"></a>Checking out the results</h2><p>Below I’ve plotted some of the test images along with their reconstructions. For the most part these look pretty good except for some blurriness in some parts.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">fig, axes = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">10</span>, sharex=<span class="keyword">True</span>, sharey=<span class="keyword">True</span>, figsize=(<span class="number">20</span>,<span class="number">4</span>))</div><div class="line">in_imgs = mnist.test.images[:<span class="number">10</span>]</div><div class="line">reconstructed, compressed = sess.run([decoded, encoded], feed_dict=&#123;inputs_: in_imgs&#125;)</div><div class="line"></div><div class="line"><span class="keyword">for</span> images, row <span class="keyword">in</span> zip([in_imgs, reconstructed], axes):</div><div class="line">    <span class="keyword">for</span> img, ax <span class="keyword">in</span> zip(images, row):</div><div class="line">        ax.imshow(img.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">'Greys_r'</span>)</div><div class="line">        ax.get_xaxis().set_visible(<span class="keyword">False</span>)</div><div class="line">        ax.get_yaxis().set_visible(<span class="keyword">False</span>)</div><div class="line"></div><div class="line">fig.tight_layout(pad=<span class="number">0.1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sess.close()</div></pre></td></tr></table></figure>
<h2 id="Up-Next"><a href="#Up-Next" class="headerlink" title="Up Next"></a>Up Next</h2><p>We’re dealing with images here, so we can (usually) get better performance using convolution layers. So, next we’ll build a better autoencoder with convolutional layers.</p>
<p>In practice, autoencoders aren’t actually better at compression compared to typical methods like JPEGs and MP3s. But, they are being used for noise reduction, which you’ll also build.</p>

    </div>

    

    
        <div class="post-tags">
            <i class="fa fa-tags" aria-hidden="true"></i>
            <a href="/tags/Deeplearning/">#Deeplearning</a>
        </div>
    

    <!-- Comments -->
    

</div>
        </section>

    </div>
</div>

</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    Supported by Hexo
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2017/07/05/language-translation/">language-translation</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2017/06/22/Autoencoder/">Autoencoder</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2015/12/31/first-post/">DigitalOcean&#39;s First Post</a>
            </li>
            
        </ul>
    </div>



            
<div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 footer-categories">
    <h2>Categories</h2>
    <ul>
        
        <li>
            <a class="footer-post" href="/categories/Hexo/">Hexo</a>
        </li>
        
    </ul>
</div>

        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    
                    <li class="list-inline-item">
                        <a href="https://twitter.com/?lang=en">
                            <span class="footer-icon-container">
                                <i class="fa fa-twitter"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.facebook.com/">
                            <span class="footer-icon-container">
                                <i class="fa fa-facebook"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.instagram.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-instagram"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Milkrong. All right reserved 
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>